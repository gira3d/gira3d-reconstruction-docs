{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Cloud Modeling using Self-Organizing Gaussian Mixture Models (SOGMM)\n",
    "This tutorial presents modeling a point cloud using the SOGMM approach presented in [1].\n",
    "We assume that a depth-intensity point cloud with $N$ points (i.e., point cloud is a set of\n",
    "$N$ four-dimensional points $\\mathbf{x}$) is given. The output is a Gaussian Mixture Model (GMM)\n",
    "of the point cloud that can be used for:\n",
    "1. Inference for intensity image reconstruction\n",
    "2. Dense sampling for 3D point cloud reconstruction \n",
    "\n",
    "## Input\n",
    "For the purposes of this tutorial, download the point cloud data from\n",
    "[this](https://cmu.box.com/s/9v7v1knt9iswui2518c6qpqtzdqnf2v5) link.  The\n",
    "downloaded zip folder contains point cloud data from a few frames of the\n",
    "`stonewall`, `copyroom`, and `lounge` ICL-NUIM datasets [2].\n",
    "\n",
    "Extract the zip folder. You will get a folder with files named like this:\n",
    "\n",
    "```\n",
    "gira3d-tutorial-data\n",
    "├── pcd_copyroom_2364_decimate_1_0.pcd\n",
    "├── pcd_copyroom_2364_decimate_2_0.pcd\n",
    "└── ...\n",
    "```\n",
    "The files are named as `pcd_<dataset-name>_<frame-number>_decimate_<decimation_amount>.pcd`.\n",
    "Here, decimation of 1.0 means the original image of size `640 x 480` was used to generate the point cloud.\n",
    "Likewise, decimations of `2.0`, `3.0`, and `4.0` correspond to image sizes `320 x 240`, `213 x 160`, and\n",
    "`160 x 120` respectively.\n",
    "\n",
    "For the purposes of this tutorial, we limit to the frames provided in the folder above. However, the\n",
    "methodology will work on any registered depth-intensity image pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning the SOGMM Model\n",
    "We start by importing the run time dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "from sogmm_py.utils import read_log_trajectory, o3d_to_np, np_to_o3d\n",
    "from sogmm_py.vis_open3d import VisOpen3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this tutorial, we will use frame `1763` of the `lounge` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 1763\n",
    "datasetname = 'lounge'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import a ground truth point cloud from the dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcld_gt = o3d.io.read_point_cloud('./gira3d-tutorial-data/pcd_' +\n",
    "                                  str(datasetname) +\n",
    "                                  '_' + str(frame) +\n",
    "                                  '_decimate_1_0.pcd', format='pcd')\n",
    "pcld_gt_np = o3d_to_np(pcld_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the ground truth SE(3) pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = read_log_trajectory('./gira3d-tutorial-data/' +\n",
    "                           str(datasetname) + '-traj.log')\n",
    "pcld_pose = traj[frame].pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the intrinsics matrix and width and height variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.eye(3)\n",
    "K[0, 0] = 525.0\n",
    "K[1, 1] = 525.0\n",
    "K[0, 2] = 319.5\n",
    "K[1, 2] = 239.5\n",
    "\n",
    "W = (int)(640)\n",
    "H = (int)(480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize, please use our python wrapper over the Open3D visualizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = VisOpen3D(visible=True)\n",
    "vis.visualize_pcld(pcld_gt, pcld_pose, K, W, H)\n",
    "vis.render()\n",
    "del vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see an interactive Open3D window that shows the depth-intensity point cloud and the camera frustrum:\n",
    "![Ground Truth Point Cloud](results/sogmm-tut-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the SOGMM method produces a generative model of the point cloud, we can train it on decimated point clouds. In this example, let us use a decimation of `4.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "deci = 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the decimated point cloud from the dataset folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcld_deci = o3d.io.read_point_cloud('./gira3d-tutorial-data/pcd_' +\n",
    "                                  str(datasetname) +\n",
    "                                  '_' + str(frame) +\n",
    "                                  '_decimate_' +\n",
    "                                  str(deci).replace('.', '_') +\n",
    "                                  '.pcd', format='pcd')\n",
    "pcld_deci_np = o3d_to_np(pcld_deci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the intrinsics matrix and width and height variables corresponding to the decimation factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_d = np.eye(3)\n",
    "K_d[0, 0] = 525.0/deci\n",
    "K_d[1, 1] = 525.0/deci\n",
    "K_d[0, 2] = 319.5/deci\n",
    "K_d[1, 2] = 239.5/deci\n",
    "\n",
    "W_d = (int)(640/deci)\n",
    "H_d = (int)(480/deci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the decimated point cloud the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = VisOpen3D(visible=True)\n",
    "vis.visualize_pcld(pcld_deci, pcld_pose, K_d, W_d, H_d)\n",
    "vis.render()\n",
    "del vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decimated point cloud looks like this:\n",
    "![Decimated Point Cloud](results/sogmm-tut-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we learn a SOGMM on the decimated point cloud. Both CPU-only and GPU-accelerated cases are supported. Both of these modules can be accessed through the `SOGMM` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sogmm_py.sogmm import SOGMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOGMM CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute platform is CPU\n",
      "CPU times: user 2min 6s, sys: 8.13 s, total: 2min 14s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sg_cpu = SOGMM(bandwidth=0.02, compute='CPU')\n",
    "model_cpu = sg_cpu.fit(pcld_deci_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the number of components automatically chosen by SOGMM for this frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cpu.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOGMM GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute platform is GPU\n",
      "CPU times: user 3.87 s, sys: 5.88 s, total: 9.75 s\n",
      "Wall time: 2.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sg_gpu = SOGMM(bandwidth=0.02, compute='GPU')\n",
    "model_gpu = sg_gpu.fit(pcld_deci_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us make sure we got the same number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gpu.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference for Intensity Image\n",
    "Intensity image can be constructed using the conditional GMM as follows. For more details on how the conditional distribution is computed, please refer to [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 468 ms, total: 1min 34s\n",
      "Wall time: 5.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_, expected_intensities, _ = model_gpu.color_conditional(pcld_gt_np[:, 0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`expected_intensities` contains the expected intensity values at the ground truth 3D points. Let us visualize these reconstructed intensity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_pcld = np.zeros(pcld_gt_np.shape)\n",
    "recon_pcld[:, 0:3] = pcld_gt_np[:, 0:3] # we are constructing intensity image on gt 3D points\n",
    "recon_pcld[:, 3] = np.squeeze(expected_intensities)\n",
    "\n",
    "vis = VisOpen3D(visible=True)\n",
    "vis.visualize_pcld(np_to_o3d(recon_pcld), pcld_pose, K, W, H)\n",
    "vis.render()\n",
    "del vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Reconstructed Point Cloud](results/sogmm-tut-3.png)\n",
    "\n",
    "Higher accuracy can be achieved if the learning is performed at a lower `deci` value (at the cost of higher computation time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense sampling for 3D point cloud reconstruction\n",
    "Dense sampling from the 4D GMM can be performed using the usual Box-Mueller sampling method [3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_pcld = sg_gpu.joint_dist_sample(pcld_gt_np.shape[0]) # sample 4D points from the model\n",
    "vis = VisOpen3D(visible=True)\n",
    "vis.visualize_pcld(np_to_o3d(resampled_pcld), pcld_pose, K, W, H)\n",
    "vis.render()\n",
    "del vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Resampled Point Cloud](results/sogmm-tut-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Measures\n",
    "We support computing the following:\n",
    "1. Peak Signal-To-Noise Ratio (PSNR): To measure the accuracy of intensity image reconstruction.\n",
    "2. Structure Similarity Index Measure (SSIM): To measure the accuracy of intensity image reconstruction.\n",
    "3. F-score: To measure the accuracy of resampled point cloud.\n",
    "4. Precision: To measure the accuracy of resampled point cloud.\n",
    "5. Recall: To measure the accuracy of resampled point cloud.\n",
    "6. Mean Reconstruction Error (MRE): To measure the accuracy of resampled point cloud.\n",
    "7. Std. Dev. Reconstruction Error: To measure the accuracy of resampled point cloud.\n",
    "8. Memory: To measure the compactness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fscore 0.963304 precision 0.977305 recall 0.949698 recon. mean 0.002654 recon. std. dev. 0.002685\n",
      "psnr 28.332349 ssim 0.869796\n"
     ]
    }
   ],
   "source": [
    "from sogmm_py.utils import calculate_depth_metrics, calculate_color_metrics\n",
    "fsc, pre, re, rm, rs = calculate_depth_metrics(pcld_gt, np_to_o3d(resampled_pcld))\n",
    "print(\"fscore %f precision %f recall %f recon. mean %f recon. std. dev. %f\" % (fsc, pre, re, rm, rs))\n",
    "\n",
    "from sogmm_py.utils import ImageUtils\n",
    "iu = ImageUtils(K) # image manipulation utility\n",
    "_, gt_g = iu.pcld_wf_to_imgs(pcld_pose, pcld_gt_np) # project gt pcld on camera\n",
    "if np.isnan(gt_g).any():\n",
    "    gt_g = np.nan_to_num(gt_g)\n",
    "_, pr_g = iu.pcld_wf_to_imgs(pcld_pose, recon_pcld) # project recon pcld on camera\n",
    "if np.isnan(pr_g).any():\n",
    "    pr_g = np.nan_to_num(pr_g)\n",
    "psnr, ssim = calculate_color_metrics(gt_g, pr_g) # compare the intensity images\n",
    "print(\"psnr %f ssim %f\" % (psnr, ssim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory 38340 bytes\n"
     ]
    }
   ],
   "source": [
    "# computing memory usage\n",
    "M = model_gpu.n_components_\n",
    "mem_bytes = 4 * M * (1 + 10 + 4)\n",
    "print('memory %d bytes' % (mem_bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] K. Goel, N. Michael, and W. Tabib, “Probabilistic Point Cloud Modeling via Self-Organizing Gaussian Mixture Models,” IEEE Robotics and Automation Letters, vol. 8, no. 5, pp. 2526–2533, May 2023, doi: 10.1109/LRA.2023.3256923.\n",
    "\n",
    "[2] Q.-Y. Zhou and V. Koltun, “Dense scene reconstruction with points of interest,” ACM Trans. Graph., vol. 32, no. 4, pp. 1–8, Jul. 2013, doi: 10.1145/2461912.2461919.\n",
    "\n",
    "[3] C. M. Bishop and N. M. Nasrabadi, Pattern recognition and machine\n",
    "learning. Springer, 2006, vol. 4, no. 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
